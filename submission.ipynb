{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./stp-gsr')  # Add the directory to Python path\n",
    "\n",
    "from src.models.stp_gsr import STPGSR\n",
    "from src.dual_graph_utils import revert_dual\n",
    "from src.dataset import load_dataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from evaluation import evaluate_matrices\n",
    "from MatrixVectorizer import MatrixVectorizer\n",
    "from mlp_baseline import NaiveMLP\n",
    "\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = {\n",
    "    'defaults': ['_self_', 'dataset: custom', 'model: stp_gsr'],\n",
    "    \n",
    "    'dataset': {\n",
    "        'name': 'custom',\n",
    "        'n_samples': 167,\n",
    "        'n_source_nodes': 160,\n",
    "        'n_target_nodes': 268,\n",
    "        'node_feat_init': 'adj',\n",
    "        'node_feat_dim': 160  # same as n_source_nodes\n",
    "    },\n",
    "    \n",
    "    'model': {\n",
    "        'name': 'stp_gsr',\n",
    "        'target_edge_initializer': {\n",
    "            'num_heads': 4,\n",
    "            'edge_dim': 1,\n",
    "            'dropout': 0.2,\n",
    "            'beta': False\n",
    "        },\n",
    "        'dual_learner': {\n",
    "            'in_dim': 1,\n",
    "            'out_dim': 1,\n",
    "            'num_heads': 1,\n",
    "            'dropout': 0.2,\n",
    "            'beta': False\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'experiment': {\n",
    "        'n_epochs': 60,\n",
    "        'batch_size': 16,\n",
    "        'lr': 0.001,\n",
    "        'log_val_loss': False,\n",
    "        'base_dir': 'results',\n",
    "        'run_name': 'run1',\n",
    "        'kfold': {\n",
    "            'n_splits': 3,\n",
    "            'shuffle': True,\n",
    "            'random_state': 42\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "config = OmegaConf.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STPGSR(\n",
       "  (target_edge_initializer): TargetEdgeInitializer(\n",
       "    (residual_proj): Linear(in_features=160, out_features=268, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0): TransformerConv(160, 16, heads=4)\n",
       "      (1): TransformerConv(64, 67, heads=4)\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0): GraphNorm(160)\n",
       "      (1): GraphNorm(64)\n",
       "    )\n",
       "  )\n",
       "  (dual_learner): DualGraphLearner(\n",
       "    (conv1): TransformerConv(1, 1, heads=1)\n",
       "    (bn1): GraphNorm(1)\n",
       "    (out_proj): Linear(in_features=1, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test data and the model, and evaluate the model on the test data.\n",
    "source_data, target_data = load_dataset(config)\n",
    "MODEL_FILE_NAME = \"stp-gsr/results/stp_gsr_residual_2layers_preactivation_no_graph_conv_whole_data/custom/run1/fold_1/model.pth\"\n",
    "\n",
    "model = STPGSR(config)\n",
    "model.load_state_dict(torch.load(MODEL_FILE_NAME))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "STPGSR.forward() missing 1 required positional argument: 'target_mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Predict the test data\u001b[39;00m\n\u001b[32m      5\u001b[39m n_target_nodes = config.dataset.n_target_nodes  \u001b[38;5;66;03m# n_t\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m y_pred = revert_dual(model_pred, n_target_nodes)    \u001b[38;5;66;03m# (n_t, n_t)\u001b[39;00m\n\u001b[32m      8\u001b[39m y_pred = y_pred.cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/mjh24/dgl-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/mjh24/dgl-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: STPGSR.forward() missing 1 required positional argument: 'target_mat'"
     ]
    }
   ],
   "source": [
    "# Change test data to torch tensor\n",
    "n_target_nodes = config.dataset.n_target_nodes  # n_t\n",
    "    \n",
    "eval_output = []\n",
    "with torch.no_grad():\n",
    "    for source, target in zip(source_data, target_data):\n",
    "        source_g = source['pyg']    \n",
    "        target_m = target['mat']    # (n_t, n_t)\n",
    "        print(target_m)\n",
    "        model_pred, model_target = model(source_g, target_m) \n",
    "\n",
    "        pred_m = revert_dual(model_pred, n_target_nodes)    # (n_t, n_t)\n",
    "        pred_m = pred_m.cpu().numpy()\n",
    "\n",
    "\n",
    "        eval_output.append(pred_m)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "return eval_output, eval_loss\n",
    "\n",
    "# Predict the test data\n",
    "n_target_nodes = config.dataset.n_target_nodes  # n_t\n",
    "model_pred = model(test_data)\n",
    "y_pred = revert_dual(model_pred, n_target_nodes)    # (n_t, n_t)\n",
    "y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4007136,)\n"
     ]
    }
   ],
   "source": [
    "# flatten\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y_pred = y_pred.flatten()\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction saved to prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert tensor to csv\n",
    "df = pd.DataFrame({\n",
    "    'ID': np.arange(1, len(y_pred)+1),\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "df.to_csv('prediction.csv', index=False)\n",
    "print('Prediction saved to prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
