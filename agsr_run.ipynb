{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"agsr_net\") \n",
    "from agsr_net import preprocessing\n",
    "from agsr_net.model import AGSRNet\n",
    "from agsr_net.train import train, test\n",
    "import argparse\n",
    "from sklearn.model_selection import KFold\n",
    "from MatrixVectorizer import MatrixVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 200  \n",
    "        self.lr = 0.0001   \n",
    "        self.lmbda = 0.1 \n",
    "        self.lr_dim = 160     \n",
    "        self.hr_dim = 268  \n",
    "        self.hidden_dim = 320 \n",
    "        self.padding = 26 \n",
    "        self.mean_dense = 0.0    \n",
    "        self.std_dense = 0.01      \n",
    "        self.mean_gaussian = 0.0  \n",
    "        self.std_gaussian = 0.1\n",
    "\n",
    "ks = [0.9, 0.7, 0.6, 0.5]\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_TRAIN_DATA_PATH = \"data/lr_train.csv\"\n",
    "LR_TEST_DATA_PATH = \"data/lr_test.csv\"\n",
    "HR_TRAIN_DATA_PATH = \"data/hr_train.csv\"\n",
    "\n",
    "df_lr_train = pd.read_csv(LR_TRAIN_DATA_PATH)\n",
    "df_lr_test = pd.read_csv(LR_TEST_DATA_PATH)\n",
    "df_hr_train = pd.read_csv(HR_TRAIN_DATA_PATH)\n",
    "\n",
    "v_lr_train = np.zeros((len(df_lr_train), 160, 160))\n",
    "v_lr_test = np.zeros((len(df_lr_test), 160, 160))\n",
    "v_hr_train = np.zeros((len(df_hr_train), 268, 268))\n",
    "\n",
    "mv = MatrixVectorizer()\n",
    "\n",
    "for i, row in enumerate(df_lr_train.values):\n",
    "    v_lr_train[i] = mv.anti_vectorize(row, 160)\n",
    "\n",
    "for i, row in enumerate(df_lr_test.values):\n",
    "    v_lr_test[i] = mv.anti_vectorize(row, 160)\n",
    "\n",
    "for i, row in enumerate(df_hr_train.values):\n",
    "    v_hr_train[i] = mv.anti_vectorize(row, 268)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/3\n",
      "(111, 160, 160)\n",
      "(111, 268, 268)\n",
      "<class 'numpy.ndarray'>\n",
      "  Training samples: 111\n",
      "  Validation samples: 56\n",
      "Discriminator(\n",
      "  (dense_1): Dense()\n",
      "  (relu_1): ReLU()\n",
      "  (dense_2): Dense()\n",
      "  (relu_2): ReLU()\n",
      "  (dense_3): Dense()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This function was deprecated since version 1.9 and is now removed. The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n\nL, _ = torch.symeig(A, upper=upper) should be replaced with:\nL = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n\nand\n\nL, V = torch.symeig(A, eigenvectors=True) should be replaced with:\nL, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# print(X_train.shape)\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# print(y_train.shape)\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# model = model(\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#         dropout_rate=0.3\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     32\u001b[39m model = AGSRNet(ks, args)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m test(model, X_val, y_val, args)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\agsr_net\\train.py:35\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, subjects_adj, subjects_labels, args)\u001b[39m\n\u001b[32m     31\u001b[39m padded_hr = torch.from_numpy(hr).type(torch.FloatTensor)\n\u001b[32m     33\u001b[39m eig_val_hr, U_hr = torch.linalg.eigh(padded_hr, UPLO=\u001b[33m'\u001b[39m\u001b[33mU\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m model_outputs, net_outs, start_gcn_outs, layer_outs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhr_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m mse_loss = args.lmbda * criterion(net_outs, start_gcn_outs) + criterion(\n\u001b[32m     39\u001b[39m     model.layer.weights, U_hr) + criterion(model_outputs, padded_hr)\n\u001b[32m     41\u001b[39m error = criterion(model_outputs, padded_hr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\agsr_net\\model.py:32\u001b[39m, in \u001b[36mAGSRNet.forward\u001b[39m\u001b[34m(self, lr, lr_dim, hr_dim)\u001b[39m\n\u001b[32m     28\u001b[39m A = normalize_adj_torch(lr).type(torch.FloatTensor)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m.net_outs, \u001b[38;5;28mself\u001b[39m.start_gcn_outs = \u001b[38;5;28mself\u001b[39m.net(A, I)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28mself\u001b[39m.outputs, \u001b[38;5;28mself\u001b[39m.Z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet_outs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mself\u001b[39m.hidden1 = \u001b[38;5;28mself\u001b[39m.gc1(\u001b[38;5;28mself\u001b[39m.Z, \u001b[38;5;28mself\u001b[39m.outputs)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mself\u001b[39m.hidden2 = \u001b[38;5;28mself\u001b[39m.gc2(\u001b[38;5;28mself\u001b[39m.hidden1, \u001b[38;5;28mself\u001b[39m.outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\agsr_net\\layers.py:26\u001b[39m, in \u001b[36mGSRLayer.forward\u001b[39m\u001b[34m(self, A, X)\u001b[39m\n\u001b[32m     24\u001b[39m lr_dim = lr.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     25\u001b[39m f = X\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m eig_val_lr, U_lr = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msymeig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigenvectors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# U_lr = torch.abs(U_lr)\u001b[39;00m\n\u001b[32m     29\u001b[39m eye_mat = torch.eye(lr_dim).type(torch.FloatTensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olly\\repos\\dgl-project\\.venv\\Lib\\site-packages\\torch\\_linalg_utils.py:118\u001b[39m, in \u001b[36m_symeig\u001b[39m\u001b[34m(input, eigenvectors, upper, out)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_symeig\u001b[39m(\n\u001b[32m    112\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    113\u001b[39m     eigenvectors=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m     out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    117\u001b[39m ) -> Tuple[Tensor, Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis function was deprecated since version 1.9 and is now removed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    120\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe default behavior has changed from using the upper triangular portion of the matrix by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto using the lower triangular portion.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mL, _ = torch.symeig(A, upper=upper) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshould be replaced with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mL = torch.linalg.eigvalsh(A, UPLO=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mU\u001b[39m\u001b[33m'\u001b[39m\u001b[33m if upper else \u001b[39m\u001b[33m'\u001b[39m\u001b[33mL\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mL, V = torch.symeig(A, eigenvectors=True) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshould be replaced with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mL, V = torch.linalg.eigh(A, UPLO=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mU\u001b[39m\u001b[33m'\u001b[39m\u001b[33m if upper else \u001b[39m\u001b[33m'\u001b[39m\u001b[33mL\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: This function was deprecated since version 1.9 and is now removed. The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n\nL, _ = torch.symeig(A, upper=upper) should be replaced with:\nL = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n\nand\n\nL, V = torch.symeig(A, eigenvectors=True) should be replaced with:\nL, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L')"
     ]
    }
   ],
   "source": [
    "k_folds = 3\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "X = v_lr_train\n",
    "y = v_hr_train\n",
    "\n",
    "fold_metrics = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Split data for this fold\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    print(X_train.shape)    \n",
    "    print(y_train.shape)\n",
    "\n",
    "    print(type(X_train))\n",
    "\n",
    "\n",
    "    print(f\"  Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"  Validation samples: {X_val.shape[0]}\")\n",
    "\n",
    "    # print(X_train.shape)\n",
    "    # print(y_train.shape)\n",
    "    # model = model(\n",
    "    #         input_dim=12720,\n",
    "    #         hidden_dims=[4096, 2048, 1024, 512],\n",
    "    #         output_dim=35778,\n",
    "    #         dropout_rate=0.3\n",
    "    # )\n",
    "\n",
    "    model = AGSRNet(ks, args)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train(model, X_train, y_train, args)\n",
    "    test(model, X_val, y_val, args)\n",
    "    break\n",
    "\n",
    "    # model, metrics = train.train(model, X_train, y_train, X_val, y_val)\n",
    "    # fold_metrics.append(metrics)\n",
    "\n",
    "    # print(f\"  Validation Loss: {metrics['val_loss']:.4f}\")\n",
    "# print(fold_metrics)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
